{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VrA-3q8gaaIP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip install -I pillow==5.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "S0Z3AQY1d2Xc",
    "colab_type": "code",
    "cellView": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# this sets up the virtual environment if gdrive doesn't contain the repo clone\n",
    "# it by setting the the if to true and modifie the path as you wish\n",
    "#@title Default title text\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "import os\n",
    "!pip install -q xlrd\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/My Drive/ADL4CV')\n",
    "#!ls\n",
    "if False:\n",
    "  from getpass import getpass\n",
    "  user = getpass('GitHub user')\n",
    "  password = getpass('GitHub password')\n",
    "  os.environ['GitHub_AUTH'] = user + ':' + password\n",
    "  !git clone https://$GitHub_AUTH@github.com/Cram13/ADL4CV_Project.git\n",
    "os.chdir('ADL4CV_Project')\n",
    "!git pull origin master\n",
    "#!pip install -I pillow==5.1.0\n",
    "!pip3 install torch torchvision\n",
    "!pip3 install tensorboardX\n",
    "#!pip install PIL\n",
    "#!pip install image\n",
    "#import PIL.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JBNRMX_eUz9x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    " #!git checkout origin/master\n",
    "!git pull origin master\n",
    "#!git status\n",
    "#!git fetch\n",
    "#!git reset --hard origin/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GlPbKjYEl-1u",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#setup options for training\n",
    "from train_yolo_example import Opt\n",
    "from yolo.yolo_net import Yolo\n",
    "from yolo.loss import YoloLoss as yloss\n",
    "from train_yolo_example import loadYoloBaseWeights\n",
    "from yolo.yolo_utils import *\n",
    "\n",
    "opt = Opt()\n",
    "opt.batch_size = 10\n",
    "opt.num_epoches = 100\n",
    "opt.useCuda = True\n",
    "opt.learning_rate = 1e-4\n",
    "opt.num_workers = 4\n",
    "anchor = [(6.88, 27.44), (11.93, 58.32), (19.90, 94.92), (40.00, 195.84), (97.96, 358.62)]\n",
    "anchor[:] = [(x[0] / 32.0, x[1]/32.0) for x in anchor]\n",
    "opt.model = Yolo(0, anchors=anchor)\n",
    "loadYoloBaseWeights(opt.model, opt)\n",
    "opt.criterion = yloss(opt.model.anchors, opt.reduction, filter_fkt=filter_non_zero_gt_without_id)\n",
    "opt.log_path = './log/test_marc416'\n",
    "opt.image_size = 416\n",
    "opt.model.image_size = opt.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bzFCAyseU7my",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "path = './log/test_marc99/snapshot0004.tar'\n",
    "device = next(opt.model.parameters()).device\n",
    "opt.model.load_state_dict(torch.load(path, map_location=device)['model_state_dict'])\n",
    "opt.optimizer = torch.optim.Adam(opt.model.parameters(), lr=opt.learning_rate, betas=(opt.momentum, 0.999), weight_decay=opt.decay)\n",
    "opt.optimizer.load_state_dict(torch.load(path, map_location=device)['optimizer_state_dict'])\n",
    "#for param_group in opt.optimizer.param_groups:\n",
    "#  param_group['lr'] = 1e-4\n",
    "#opt.model.image_size = 832\n",
    "#opt.image_size = 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "06KjmanwmN70",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#fire up tensorboard in the background\n",
    "#todo make path first\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format('./log/3_yolo_lstm_832/')#opt.log_path)\n",
    ")\n",
    "get_ipython().system_raw('/content/ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "dpOHJBW6b8rV",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from yolo.yolo_utils import *\n",
    "from yolo.yolo_net import Yolo\n",
    "from yolo.loss import YoloLoss as yloss\n",
    "import torchvision\n",
    "from tensorboardX import SummaryWriter\n",
    "import shutil\n",
    "import time\n",
    "from dataset_utils.datasets.MOT_bb_singleframe import MOT_bb_singleframe\n",
    "from dataset_utils.datasets.MOT_bb_singleframe import MOT_bb_singleframe_eval\n",
    "import dataset_utils.MOT_utils as motu\n",
    "from train_yolo_example import *\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from dataset_utils.datasets.MotBBImageSingle import *\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def loadTrainEvalSet(opt):\n",
    "    dataset = MotBBImageSingle('dataset_utils/Mot17_test_single.txt', use_only_first_video=False, seq_length=1, new_height=opt.image_size, new_width=opt.image_size)\n",
    "    training_set = Subset(dataset, range(0, dataset.valid_begin))\n",
    "    eval_set = Subset(dataset, range(dataset.valid_begin, len(dataset)))\n",
    "    training_loader = DataLoader(training_set, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers,\n",
    "                              drop_last=False)\n",
    "    eval_loader = DataLoader(eval_set, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers,\n",
    "                              drop_last=False)\n",
    "    return training_set, training_loader, eval_set, eval_loader\n",
    "\n",
    "def train(opt):\n",
    "    # setup train and eval set\n",
    "    if torch.cuda.is_available() and opt.useCuda:\n",
    "        torch.cuda.manual_seed(123)\n",
    "    else:\n",
    "        torch.manual_seed(123)\n",
    "\n",
    "    training_set, training_loader, eval_set, eval_loader = loadTrainEvalSet(opt)\n",
    "\n",
    "    # log stuff\n",
    "    if os.path.isdir(opt.log_path):\n",
    "        shutil.rmtree(opt.log_path)\n",
    "    os.makedirs(opt.log_path)\n",
    "    writer = SummaryWriter(opt.log_path)\n",
    "    if torch.cuda.is_available() and opt.useCuda:\n",
    "        writer.add_graph(opt.model.cpu(), torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size))\n",
    "        opt.model.cuda()\n",
    "    else:\n",
    "        writer.add_graph(opt.model, torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size))\n",
    "\n",
    "    # write the hyperparams lr, batchsize  and imagesize in the tensorboard file\n",
    "    writer.add_text('Hyperparams',\n",
    "                    'lr: {}, \\nbatchsize: {}, \\nimg_size:{}'.format(opt.learning_rate, opt.batch_size, opt.image_size))\n",
    "\n",
    "    # loss and optimize\n",
    "    if opt.optimizer is None:\n",
    "        opt.optimizer = torch.optim.Adam(opt.model.parameters(), lr=opt.learning_rate, betas=(opt.momentum, 0.999),\n",
    "                                         weight_decay=opt.decay)\n",
    "\n",
    "    #scheduler = StepLR(opt.optimizer, step_size=1, gamma=0.75)\n",
    "    #scheduler = MultiStepLR(opt.optimizer, milestones=[5, 30, 80], gamma=0.1)\n",
    "    learning_rate_schedule = {\"0\": 1e-5, \"5\": 1e-4, \"30\": 1e-5, \"50\": 1e-6}\n",
    "\n",
    "    epoch_len = len(training_loader)\n",
    "    for epoch in range(opt.num_epoches):\n",
    "        training_set.dataset.is_training = True\n",
    "        print('num epoch: {:4d}'.format(epoch))\n",
    "        #scheduler.step()\n",
    "        \n",
    "        #if str(epoch) in learning_rate_schedule.keys():\n",
    "        #  for param_group in opt.optimizer.param_groups:\n",
    "        #    param_group['lr'] = learning_rate_schedule[str(epoch)]\n",
    "        opt.model.train()\n",
    "        for img_nr, (gt, img) in enumerate(training_loader):\n",
    "            if torch.cuda.is_available() and opt.useCuda:\n",
    "                img = Variable(img.cuda(), requires_grad=True)\n",
    "            else:\n",
    "                img = Variable(img, requires_grad=True)\n",
    "            opt.optimizer.zero_grad()\n",
    "            logits = opt.model(img)\n",
    "            loss, loss_coord, loss_conf = opt.criterion(logits, gt)\n",
    "            writeLossToSummary(writer, 'Train', loss.item(),\n",
    "                               loss_coord.item(), loss_conf.item(), epoch * epoch_len + img_nr)\n",
    "            loss.backward()\n",
    "            opt.optimizer.step()\n",
    "\n",
    "        # eval stuff\n",
    "        opt.model.eval()\n",
    "        eval_set.dataset.is_training = False\n",
    "        loss_ls = []\n",
    "        loss_coord_ls = []\n",
    "        loss_conf_ls = []\n",
    "        all_ap = []\n",
    "        all_ap1 = []\n",
    "        for te_iter, te_batch in enumerate(eval_loader):\n",
    "            te_label, te_image = te_batch\n",
    "            num_sample = len(te_label)\n",
    "            if torch.cuda.is_available() and opt.useCuda:\n",
    "                te_image = te_image.cuda()\n",
    "            with torch.no_grad():\n",
    "                te_logits = opt.model(te_image)\n",
    "                batch_loss, batch_loss_coord, batch_loss_conf = opt.criterion(te_logits, te_label)\n",
    "                for i in range(num_sample):\n",
    "                    ap = get_ap(te_logits[i], filter_non_zero_gt_without_id(te_label[i]), opt.image_size, opt.image_size, opt.model.anchors, .5)\n",
    "                    ap1 = get_ap(te_logits[i], filter_non_zero_gt_without_id(te_label[i]), opt.image_size, opt.image_size, opt.model.anchors, .8)\n",
    "                    if not np.isnan(ap):\n",
    "                        all_ap.append(ap)\n",
    "                    if not np.isnan(ap1):\n",
    "                        all_ap1.append(ap1)\n",
    "                # if te_iter % 10 ==0:\n",
    "                #    img = np.array(draw_img(te_logits, te_image[0], opt.image_size, opt.model.anchors))\n",
    "                #    print(img.shape)\n",
    "                #    print(img.dtype)\n",
    "                #    print(type(img))\n",
    "                #    writer.add_image(f'Val/{epoch}', img)\n",
    "            loss_ls.append(batch_loss * num_sample)\n",
    "            loss_coord_ls.append(batch_loss_coord * num_sample)\n",
    "            loss_conf_ls.append(batch_loss_conf * num_sample)\n",
    "        te_loss = sum(loss_ls) / eval_set.__len__()\n",
    "        te_coord_loss = sum(loss_coord_ls) / eval_set.__len__()\n",
    "        te_conf_loss = sum(loss_conf_ls) / eval_set.__len__()\n",
    "        #print('{}  {}   {}'.format(te_loss, te_coord_loss, te_conf_loss))\n",
    "        writer.add_scalar('Val/AP0.5', np.mean(np.array(all_ap)), epoch * epoch_len)\n",
    "        writer.add_scalar('Val/AP0.8', np.mean(np.array(all_ap1)), epoch * epoch_len)\n",
    "        writeLossToSummary(writer, 'Val', te_loss.item(),\n",
    "                           te_coord_loss.item(), te_conf_loss.item(), epoch * epoch_len)\n",
    "\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': opt.model.state_dict(),\n",
    "                    'optimizer_state_dict': opt.optimizer.state_dict()},\n",
    "                   opt.log_path + '/snapshot{:04d}.tar'.format(epoch))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ORfeMsdncDG0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8Vl-8i9i3El1",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from train_yolo_example import train\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WJffPoaQUfGp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#fire up tensorboard in the background\n",
    "#todo make path first\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format('./log')\n",
    ")\n",
    "get_ipython().system_raw('/content/ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Oyd5vSNEsJQR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(3600):\n",
    "  time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "MuCynQfc1LCW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TrainOnColab.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
