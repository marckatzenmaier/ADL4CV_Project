{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTMTrainOnColab.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"VrA-3q8gaaIP","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -I pillow==5.1.0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S0Z3AQY1d2Xc","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["# this sets up the virtual environment if gdrive doesn't contain the repo clone\n","# it by setting the the if to true and modifie the path as you wish\n","#@title Default title text\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","import os\n","!pip install -q xlrd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/ADL4CV')\n","#!ls\n","if False:\n","  from getpass import getpass\n","  user = getpass('GitHub user')\n","  password = getpass('GitHub password')\n","  os.environ['GitHub_AUTH'] = user + ':' + password\n","  !git clone https://$GitHub_AUTH@github.com/Cram13/ADL4CV_Project.git\n","os.chdir('ADL4CV_Project')\n","!git pull origin master\n","#!pip install -I pillow==5.1.0\n","!pip3 install torch==0.4.1 torchvision==0.2.1\n","!pip3 install tensorboardX\n","#!pip install PIL\n","#!pip install image\n","#import PIL.image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JBNRMX_eUz9x","colab_type":"code","colab":{}},"cell_type":"code","source":[" #!git checkout origin/master\n","!git pull origin master\n","#!git status\n","#!git fetch\n","#!git reset --hard origin/master"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DIEXuzH-80ZG","colab_type":"code","colab":{}},"cell_type":"code","source":["#setup options for training\n","from train_yolo_example import Opt\n","from torch.utils.data import DataLoader, Subset\n","from yolo.yolo_LSTM import YoloLSTM\n","from yolo.loss import YoloLoss\n","from train_yolo_lstm import load_Snapshot_to_yolo_LSTM#, filter_gt #,train\n","import torch\n","\n","from dataset_utils.datasets.MotBBImageSequence import *\n","from torch.utils.data import DataLoader, Subset\n","from yolo.yolo_LSTM import YoloLSTM\n","from yolo.loss import YoloLoss\n","from train_yolo_example import Opt\n","import torch.nn as nn\n","import torch\n","from yolo.yolo_encoder import YoloEncoder\n","from yolo.yolo_lstm_part import YoloLSTM_part\n","from tensorboardX import SummaryWriter\n","import shutil\n","from train_yolo_example import writeLossToSummary\n","from yolo.yolo_utils import *\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ejHHOwUm9Wyi","colab_type":"code","colab":{}},"cell_type":"code","source":["#fire up tensorboard in the background\n","#todo make path first\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format('./log/')#opt.log_path)\n",")\n","get_ipython().system_raw('/content/ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"GlPbKjYEl-1u","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def filter_non_zero_gt(gt):\n","    # used to filter only existing bb for loss\n","    return gt[gt[:, 0] != 0.0][:, 1:]\n","\n","'''opt = Opt()\n","opt.batch_size = 4\n","opt.num_epoches = 100\n","opt.useCuda = True\n","opt.learning_rate = 1e-6\n","opt.num_workers = 4\n","anchor = [(6.88, 27.44), (11.93, 58.32), (19.90, 94.92), (40.00, 195.84), (97.96, 358.62)]\n","anchor[:] = [(x[0] / 32.0, x[1]/32.0) for x in anchor]\n","opt.model = Yolo(0, anchors=anchor)\n","loadYoloBaseWeights(opt.model, opt)\n","opt.criterion = yloss(0, opt.model.anchors, opt.reduction)'''\n","opt = Opt()\n","opt.useCuda = True\n","opt.learning_rate = 1e-4\n","opt.batch_size = 4\n","anchors = [(0.43, 1.715), (0.745625, 3.645), (1.24375, 5.9325), (2.5, 12.24), (6.1225, 22.41375)]\n","opt.model = YoloLSTM(opt.batch_size, image_size=832, anchors=anchors)\n","opt.pre_trained_yolo_path = './log/2_yolo_832/snapshot0025.tar'\n","opt.image_size = 832\n","#load_Snapshot_to_yolo_LSTM(opt.model.encoder, opt)\n","opt.model.load_pretrained_weights(opt.pre_trained_yolo_path)\n","device = torch.device(\"cuda\")\n","opt.model.to(device)\n","opt.criterion = YoloLoss(opt.model.anchors, filter_fkt=filter_non_zero_gt)\n","opt.num_workers = 0\n","\n","opt.log_path = './log/test_marc99_continue'\n","#train(opt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MlxM1FKTdFkC","colab_type":"code","colab":{}},"cell_type":"code","source":["path = './log/test_marc99/snapshot0004.tar'\n","device = next(opt.model.parameters()).device\n","opt.model.load_state_dict(torch.load(path, map_location=device)['model_state_dict'])\n","opt.optimizer = torch.optim.Adam(opt.model.parameters(), lr=opt.learning_rate, betas=(opt.momentum, 0.999), weight_decay=opt.decay)\n","opt.optimizer.load_state_dict(torch.load(path, map_location=device)['optimizer_state_dict'])\n","#for param_group in opt.optimizer.param_groups:\n","#  param_group['lr'] = 1e-4\n","#opt.model.image_size = 832\n","#opt.image_size = 832"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wu1Go9fH2YER","colab_type":"code","colab":{}},"cell_type":"code","source":[" \n","def train(opt):\n","  # setup train and eval set\n","  if torch.cuda.is_available() and opt.useCuda:\n","      torch.cuda.manual_seed(123)\n","  else:\n","      torch.manual_seed(123)\n","  dataset = MotBBImageSequence('dataset_utils/Mot17_test_single.txt', use_only_first_video=False, new_height=832, new_width=832)\n","  train_data = Subset(dataset, range(0, dataset.valid_begin))\n","  valid_data = Subset(dataset, range(dataset.valid_begin, len(dataset)))\n","  train_loader = DataLoader(train_data, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)#, drop_last=True)\n","  valid_loader = DataLoader(valid_data, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers)#, drop_last=True)\n","\n","  # log stuff\n","  if os.path.isdir(opt.log_path):\n","      shutil.rmtree(opt.log_path)\n","  os.makedirs(opt.log_path)\n","  writer = SummaryWriter(opt.log_path)\n","  #fix this so that we get our graph\n","  #if torch.cuda.is_available() and opt.useCuda:\n","  #    writer.add_graph(opt.model.cpu(), torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size))\n","  #    opt.model.cuda()\n","  #else:\n","  #    writer.add_graph(opt.model, torch.rand(opt.batch_size, 3, opt.image_size, opt.image_size))\n","  writer.add_text('Hyperparams', 'lr: {}, \\nbatchsize: {}, \\nimg_size:{}'.format(opt.learning_rate, opt.batch_size, opt.image_size))\n","\n","  opt.optimizer = torch.optim.Adam(opt.model.parameters(), lr=opt.learning_rate, betas=(opt.momentum, 0.999),weight_decay=opt.decay)\n","  epoch_len = len(train_loader)\n","  print('epoch_len: {}'.format(epoch_len))\n","  for epoch in range(opt.num_epoches):\n","    print('num epoch: {:4d}'.format(epoch))\n","    opt.model.train()\n","    for img_nr, (gt, b, img, d) in enumerate(train_loader):\n","      sequence_len = gt.shape[1]\n","      opt.model.reinit_lstm(gt.shape[0])\n","      opt.optimizer.zero_grad()\n","      seq_loss, seq_loss_coord, seq_loss_conf = (0.0, 0.0, 0.0)\n","      for i in range(sequence_len):\n","        if torch.cuda.is_available() and opt.useCuda:\n","          single_gt = gt[:, i].cuda()\n","          single_img = img[:, i].cuda()\n","        else:\n","          single_gt = gt[:, i]\n","          single_img = img[:, i]\n","        #print(single_gt.shape)\n","        #print(filter_non_zero_gt(single_gt[0]).shape)\n","        logits = opt.model(single_img*255.)\n","        loss, loss_coord, loss_conf = opt.criterion(logits, single_gt)\n","        seq_loss += loss\n","        seq_loss_conf += loss_conf.item()\n","        seq_loss_coord += loss_coord.item()\n","      seq_loss.backward()#retain_graph=True)\n","      opt.optimizer.step()\n","      writeLossToSummary(writer, 'Train', seq_loss.item()/sequence_len, seq_loss_coord/sequence_len,\n","                         seq_loss_conf/sequence_len, epoch * epoch_len + img_nr)\n","\n","\n","    # eval stuff\n","    opt.model.eval()\n","    valid_len = len(valid_loader)\n","    loss_eval = 0\n","    loss_coord_eval = 0\n","    loss_conf_eval = 0\n","    all_ap = []\n","    all_ap1 = []\n","    for img_nr, (gt, b, img, d) in enumerate(valid_loader):\n","      sequence_len = gt.shape[1]\n","      opt.model.reinit_lstm(gt.shape[0])\n","      seq_loss, seq_loss_coord, seq_loss_conf = (0.0, 0.0, 0.0)\n","      for i in range(sequence_len):\n","        if torch.cuda.is_available() and opt.useCuda:\n","          single_gt = gt[:, i].cuda()\n","          single_img = img[:, i].cuda()\n","        else:\n","          single_gt = gt[:, i]\n","          single_img = img[:, i]\n","        with torch.no_grad():\n","          logits = opt.model(single_img*255.)\n","          loss, loss_coord, loss_conf = opt.criterion(logits, single_gt)\n","          for i in range(single_gt.shape[0]):\n","              ap = get_ap(logits[i], filter_non_zero_gt(single_gt[i]), opt.image_size, opt.image_size,\n","                          opt.model.anchors, .5)\n","              ap1 = get_ap(logits[i], filter_non_zero_gt(single_gt[i]), opt.image_size, opt.image_size,\n","                           opt.model.anchors, .8)\n","              if not np.isnan(ap):\n","                  all_ap.append(ap)\n","              if not np.isnan(ap1):\n","                  all_ap1.append(ap1)\n","        seq_loss += loss.item()\n","        seq_loss_conf += loss_conf.item()\n","        seq_loss_coord += loss_coord.item()\n","\n","      loss_eval += seq_loss/sequence_len\n","      loss_coord_eval += seq_loss_coord/sequence_len\n","      loss_conf_eval += seq_loss_conf/sequence_len\n","\n","\n","    writeLossToSummary(writer, 'Val', loss_eval/valid_len, loss_coord_eval/valid_len,\n","                       loss_conf_eval/valid_len, (epoch+1) * epoch_len)\n","\n","    writer.add_scalar('Val/AP0.5', np.mean(np.array(all_ap)), epoch * epoch_len)\n","    writer.add_scalar('Val/AP0.8', np.mean(np.array(all_ap1)), epoch * epoch_len)\n","    print(np.mean(np.array(all_ap)))\n","    #print('{}  {}   {}'.format(loss_eval/valid_len, loss_coord_eval/valid_len,\n","    #                           loss_conf_eval/valid_len))\n","\n","    torch.save({'epoch': epoch, 'model_state_dict': opt.model.state_dict(),\n","                'optimizer_state_dict': opt.optimizer.state_dict()},\n","               opt.log_path+'/snapshot{:04d}.tar'.format(epoch))\n","\n","  writer.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Vl-8i9i3El1","colab_type":"code","colab":{}},"cell_type":"code","source":["train(opt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oyd5vSNEsJQR","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","for i in range(3600):\n","  time.sleep(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D4e2CXORjvnd","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}